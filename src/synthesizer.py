import subprocess
import requests
import json
from pathlib import Path
from src.config import SUMMARIES_DIR, SYNTHESIS_ENGINE, OLLAMA_HOST, OLLAMA_MODEL, GEMINI_API_KEY, GEMINI_MODEL
from src.models import Paper
from src.db import db
from src.logger import logger

SYNTHESIS_PROMPT = """
You are an expert scientific synthesizer. Your task is to generate an "Extended Card" for the provided scientific paper.

**CRITICAL INSTRUCTION:** Output ONLY the Markdown content starting from the '## Research Groups' section. Do NOT include any title, internal monologue, thoughts, planning, or tool usage descriptions. 

**Output Language:** English.
**Measurement Units:** ALWAYS use the International System of Units (SI).

**Required Format (Markdown):**

## Research Groups
[List the main research groups, labs, or departments involved in the study.]

## Short Summary
[A VERY CONCISE 1-2 sentence summary of the paper's core objective and main finding.]

## Objective
- [Research question or principal hypothesis]

## Study Configuration
- **Spatial Scale:** [Description]
- **Temporal Scale:** [Description]

## Methodology and Data
- **Models used:** [e.g., ISBA, mHM, etc.]
- **Data sources:** [e.g., Satellite, observation, reanalysis]

## Main Results
- [Key findings, synthetic and quantitative]

## Contributions
- [Original value of the article with respect to existing literature]

## Funding
- [List projects, programs, and reference codes that funded this research]
"""

class Synthesizer:
    def __init__(self):
        self.engine = SYNTHESIS_ENGINE

    def synthesize(self, paper: Paper, full_text: str, is_full_text: bool) -> bool:
        """
        Synthesize the paper content using the configured engine.
        """
        year = paper.published.strftime("%Y")
        save_dir = SUMMARIES_DIR / year
        save_dir.mkdir(parents=True, exist_ok=True)
        save_path = save_dir / paper.to_filename()
        
        logger.info(f"Synthesizing summary for: {paper.title} using {self.engine}")
        
        content = ""
        model_display = ""
        
        try:
            if self.engine == "ollama":
                content = self._synthesize_ollama(full_text)
                model_display = f"{OLLAMA_MODEL} (Ollama)"
            elif self.engine == "gemini-api":
                content = self._synthesize_gemini_api(full_text)
                model_display = f"{GEMINI_MODEL} (Google API)"
            else:
                content = self._synthesize_gemini(full_text)
                model_display = "Gemini CLI"
        except Exception as e:
            msg = f"Synthesis engine error: {e}"
            logger.error(msg)
            db.add_event("ERROR", msg)
            return False
            
        if not content:
            db.add_event("ERROR", f"Empty synthesis for: {paper.title}")
            return False

        # 1. Generate Deterministic Title
        title_line = self._generate_deterministic_title(paper)
        
        # 2. Build Deterministic Identification Section
        id_section = self._generate_deterministic_id_section(paper)

        # 3. Add Warning if not full text (Wrapped for generator parsing)
        warning_msg = ""
        if not is_full_text:
            warning_msg = "<!-- warning_start -->\n> ⚠️ **Warning:** This summary was generated from the **abstract only**, as the full text was not available.\n<!-- warning_end -->\n"

        # 4. Assemble Final Content
        # Remove any main title (#) or blank lines at the start
        lines = content.splitlines()
        while lines and (lines[0].strip().startswith("#") or not lines[0].strip()):
            lines.pop(0)
        
        # Ensure ## Research Groups header exists if the first kept line isn't it
        if lines and not lines[0].strip().startswith("## Research Groups"):
            lines.insert(0, "## Research Groups")
        
        final_content = f"{title_line}\n\n{warning_msg}{id_section}\n\n" + "\n".join(lines)

        # 5. Append BibTeX
        bibtex = self._generate_bibtex(paper)
        final_content += f"\n\n## Citation\n```bibtex\n{bibtex}\n```"

        # 6. Append Footer
        footer = f"\n\n---\n*Generated by [BiblioAssistant](https://github.com/bitic/biblioassistant/) using {model_display}*"
        final_content += footer

        # Save the result
        try:
            with open(save_path, "w") as f:
                f.write(final_content)
                # Append metadata for generator
                f.write(f"\n\n<!-- metadata:original_link:{paper.link} -->")
            
            paper.is_processed = True
            paper.summary_path = str(save_path)
            logger.info(f"Summary saved to {save_path}")
            return True
        except Exception as e:
            logger.error(f"Error saving summary: {e}")
            return False

    def _generate_bibtex(self, paper: Paper) -> str:
        """Generates a BibTeX entry for the paper."""
        year = paper.published.strftime("%Y")
        
        # Generate a citation key
        first_author_surname = "Unknown"
        if paper.authors:
            first_author = paper.authors[0]
            if "," in first_author:
                first_author_surname = first_author.split(",")[0].strip()
            else:
                first_author_surname = first_author.split(" ")[-1].strip()
        
        # Clean surname
        first_author_surname = "".join(c for c in first_author_surname if c.isalnum())
        
        # First word of title (ignoring stop words?)
        title_word = "Article"
        words = [w for w in paper.title.split() if w.lower() not in {"a", "an", "the", "on", "in", "of"}]
        if words:
            title_word = "".join(c for c in words[0] if c.isalnum())
            
        citation_key = f"{first_author_surname}{year}{title_word}"
        
        # Format authors
        formatted_authors = []
        for author in paper.authors:
            # If "Last, First" -> keep
            # If "First Last" -> convert to "Last, First"
            if "," not in author:
                parts = author.split(" ")
                if len(parts) > 1:
                    last = parts[-1]
                    first = " ".join(parts[:-1])
                    formatted_authors.append(f"{last}, {first}")
                else:
                    formatted_authors.append(author)
            else:
                formatted_authors.append(author)
        
        authors_str = " and ".join(formatted_authors)
        
        bibtex = f"@article{{{citation_key},\n"
        bibtex += f"  author = {{{authors_str}}},\n"
        bibtex += f"  title = {{{paper.title}}},\n"
        bibtex += f"  journal = {{{paper.source}}},\n"
        bibtex += f"  year = {{{year}}}"
        
        if paper.doi:
            bibtex += f",\n  doi = {{{paper.doi}}}"
            bibtex += f",\n  url = {{https://doi.org/{paper.doi}}}"
        elif paper.link:
            bibtex += f",\n  url = {{{paper.link}}}"
            
        bibtex += "\n}"
        return bibtex

    def _generate_deterministic_title(self, paper: Paper) -> str:
        """Constructs: # Surname [et al.] (YYYY) Article Title"""
        author_str = "Unknown"
        if paper.authors:
            # Extract surname from first author
            first_author = paper.authors[0]
            # Handle "LastName, FirstName" or "FirstName LastName"
            if "," in first_author:
                surname = first_author.split(",")[0].strip()
            else:
                # Basic heuristic: last word is surname
                parts = first_author.split(" ")
                surname = parts[-1].strip()
            
            if len(paper.authors) > 1:
                author_str = f"{surname} et al."
            else:
                author_str = surname
        
        year = paper.published.strftime("%Y")
        return f"# {author_str} ({year}) {paper.title}"

    def _generate_deterministic_id_section(self, paper: Paper) -> str:
        """Constructs the Identification section deterministically."""
        year = paper.published.strftime("%Y")
        full_date = paper.published.strftime("%Y-%m-%d")
        authors_list = ", ".join(paper.authors) if paper.authors else "Unknown"
        doi_link = f"https://doi.org/{paper.doi}" if paper.doi else paper.link
        
        section = f"## Identification\n"
        section += f"- **Journal:** {paper.source}\n"
        section += f"- **Year:** {year}\n"
        section += f"- **Date:** {full_date}\n"
        section += f"- **Authors:** {authors_list}\n"
        section += f"- **DOI:** [{paper.doi}]({doi_link})\n"
        
        return section

    def _synthesize_gemini_api(self, full_text: str) -> str:
        """Uses the new Google GenAI SDK."""
        if not GEMINI_API_KEY:
            logger.error("GEMINI_API_KEY not found in environment.")
            return ""
            
        try:
            from google import genai
            client = genai.Client(api_key=GEMINI_API_KEY)
            
            response = client.models.generate_content(
                model=GEMINI_MODEL,
                contents=f"{SYNTHESIS_PROMPT}\n\nPAPER TEXT:\n{full_text}",
                config={
                    "temperature": 0.2,
                }
            )
            
            if response and response.text:
                # Record usage
                try:
                    usage = response.usage_metadata
                    # Costs for Gemini 1.5 Flash (approximate)
                    # Input: $0.10 / 1M tokens, Output: $0.40 / 1M tokens
                    cost = (usage.prompt_token_count * 0.10 / 1_000_000) + (usage.candidates_token_count * 0.40 / 1_000_000)
                    db.add_usage(GEMINI_MODEL, usage.prompt_token_count, usage.candidates_token_count, cost)
                except Exception as e:
                    logger.warning(f"Could not record usage: {e}")

                return self._clean_output(response.text)
            return ""
        except Exception as e:
            logger.error(f"Gemini API synthesis error: {e}")
            return ""

    def _synthesize_ollama(self, full_text: str) -> str:
        url = f"{OLLAMA_HOST}/api/generate"
        prompt = f"{SYNTHESIS_PROMPT}\n\nPAPER TEXT:\n{full_text}"
        
        payload = {
            "model": OLLAMA_MODEL,
            "prompt": prompt,
            "stream": False,
            "options": {
                "num_ctx": 12288, # Increased context for long papers
                "temperature": 0.3
            }
        }

        try:
            response = requests.post(url, json=payload, timeout=900) # 15 min timeout for synthesis
            response.raise_for_status()
            
            data = response.json()
            raw_response = data.get("response", "")
            
            # Record usage
            try:
                prompt_tokens = data.get("prompt_eval_count", 0)
                completion_tokens = data.get("eval_count", 0)
                db.add_usage(OLLAMA_MODEL, prompt_tokens, completion_tokens, 0.0)
            except Exception as e:
                logger.warning(f"Could not record Ollama usage: {e}")

            # Clean think blocks if using deepseek-r1 or similar
            clean_content = self._clean_output(raw_response)
            return clean_content
            
        except Exception as e:
            logger.error(f"Ollama synthesis error: {e}")
            return ""

    def _synthesize_gemini(self, full_text: str) -> str:
        try:
            # Prepare the command
            # --allowed-tools "" prevents the agent from trying to use tools
            cmd = ["gemini", "-p", SYNTHESIS_PROMPT, "--allowed-tools", ""]
            
            process = subprocess.Popen(
                cmd,
                stdin=subprocess.PIPE,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True
            )
            
            stdout, stderr = process.communicate(input=full_text)
            
            if process.returncode != 0:
                logger.error(f"Gemini CLI error: {stderr}")
                return ""
            
            return self._clean_output(stdout)
            
        except Exception as e:
            logger.error(f"Error during Gemini synthesis: {e}")
            return ""

    def _clean_output(self, text: str) -> str:
        """
        Cleans the LLM output (removes <think> blocks, finds markdown start).
        """
        # Remove <think>...</think> blocks common in Deepseek models
        if "<think>" in text:
            import re
            text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL)
        
        lines = text.splitlines()
        clean_lines = []
        found_start = False
        
        for line in lines:
            # The actual content starts with ## Research Groups
            if not found_start:
                if "## Research Groups" in line:
                    found_start = True
                    clean_lines.append(line)
            else:
                clean_lines.append(line)
        
        result = "\n".join(clean_lines).strip()
        
        if not result:
            logger.warning("Empty content after cleaning. Returning raw text as fallback (trimmed).")
            # If cleaning failed (no ## header), return trimmed text if it looks reasonable
            if len(text.strip()) > 100:
                return text.strip()
            return ""
            
        return result